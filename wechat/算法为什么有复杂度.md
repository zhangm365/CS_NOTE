2021年12月吴军老师的新作《计算之魂》正式出版了，个人第一时间拿到了新书。最近阅读此书，启发很大。吴军老师不仅是著名的计算机科学家，而且把计算机体系知识能系统通俗地讲出来，确实厉害，强烈推荐此书。



这个问题在一次面试中被面试官问到了。

纵观计算机的发展史，有三个人做出了巨大的贡献：

1. 图灵提出了计算机的数学模型，后来有了以他命令的计算机界的诺贝尔奖：图灵奖；
2. 冯**·**诺依曼确定了计算机通用的系统结构：即计算机包括输入设备、存储器、运算器、处理器和输出设备五大部件；
3. 高德纳奠定了计算机算法的基础，即我们通常说的：程序 = 数据结构 + 算法。因此，程序是计算机必不可少的部分，而程序的灵魂在于算法。



那么计算机算法为什么有时间复杂度的概念呢？

在 20 世纪 50 年代，在早期的计算机中，计算机的结构设计非常繁琐且成本昂贵，但计算效率非常低下。究其原因，早期的电子计算机，人们过分关注硬件，而忽视了软件的基础性能。



之后的 10 年里，由于计算机开始在商业上开始普及，那么程序设计得是否合理、效率的高低、占用硬件资源的多少等指标就需要人们认真考虑了。而奠定计算机算法理论基础的人正是高德纳。



高德纳在计算机领域做出了许多突出的贡献，有以下几件事闻名于世：

1. 计算机算法的鼻祖，提出了评估计算机算法的标准。即计算机算法中为什么会有时间复杂度的概念？就是我们今天分享的内容；
2. 计算机圣经 ---《计算机程序设计艺术》三卷作者；
3. 迄今为止最年轻的图灵奖获得者；
4. 发明了 `Tex` 排版软件，这是一场出版界的伟大革命，是全球学术排版的不二规范；
5. 编程非常厉害。他在写程序时，力争算法在设计时就达到最优。



在现实世界中，人们对基本的数量级是有概念的。人与人之间水平的差异、东西质量的好坏等常常是呈数量级的，一个数量级（10倍）差别固然是不小，但是对于计算机算法最终造成的差异可以忽略不计。而算法的设计稍微差了一点，则计算机运行的时间可能是差出千万倍，即“失之毫厘谬以千里”。



而人本身对大数没有什么概念，毕竟我们生活在一个小数的世界里。同理，对很快的速度也没什么概念的，我们生活在一个很慢的世界中。因此，今天的人们对计算机的高速度运行也是无感的。



如今，计算机硬件的进步速度虽然并不慢，但在一段特定的时间里，硬件的性能几乎是一个常数。因此，程序的差异就与软件的效率相关了。而程序的性能由算法决定，要评估算法的好坏，就必须先明确算法的评估指标。



在计算机内部，不搞辩证法，不懂变通，因此我们需要制定一个明确的、一致的标准来评估算法的性能。因此，计算机科学家提出了时间复杂度的概念来完成这个任务。而将时间复杂度引入计算机并严格量化衡量的正是高德纳，他也因此被誉为 “算法设计之父”。

高德纳的算法思想主要包括以下几个要点：

1. 在比较算法的快慢时，只需要考虑数量特别大，大到近乎无穷大时的情况。因为计算机发明是为了处理大量数据的；
2. 决定算法快慢的因素很多，这些因素可以被分为两类：不随数据量变化的因素；随数据量变化的因素。

举个例子，两个算法：`3N^2` 和 `100NlogN`，`N` 是数据规模。常数 `3` 和 `100` 和 `N` 的大小显然没有关系。评估算法的性能时，考虑 `N` 趋于无穷大时，只需比较 `NlogN` 和 `N^2` 的计算量。



站在计算机的角度，计算机面对的常常是上述问题。当讨论计算复杂度时，只需考虑 `N` 无穷大时且与 `N` 相关的部分。我们可以把一种算法的计算量或占用空间大小，写成 `N` 的一个函数 `f(N)` 来量化计算机算法的性能。这个函数的边界在数学上用大 `O` 概念来限制。综上，就是在计算机中提出的时间复杂度概念来衡量算法的优劣的由来。